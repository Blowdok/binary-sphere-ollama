# Sph√®re Binaire avec Citations IA g√©n√©rer dynamiquement

Une visualisation 3D immersive d'une sph√®re binaire (0 et 1) avec des citations g√©n√©r√©es par un mod√®le de langage Ollama.

![Capture d'√©cran de la Sph√®re Binaire](images/sphere-3d-ollama.png)

## üåü Fonctionnalit√©s

- Sph√®re 3D interactive avec chiffres binaires lumineux
- Affichage de l'heure et de la date en temps r√©el
- Citations g√©n√©r√©es par votre mod√®le Ollama local
- Syst√®me anti-r√©p√©tition pour les citations
- Interface visuelle √©l√©gante en noir et effets lumineux

## üìã Pr√©requis

- [Ollama](https://ollama.ai/) install√© et configur√©
- Un mod√®le Ollama (par d√©faut: `llama3.2:1b-instruct-q8_0`)
- Python 3.7+ et pip
- Un navigateur web moderne

## üöÄ Installation

   **Cloner ou t√©l√©charger ce d√©p√¥t**

   ```bash
   git clone https://github.com/Blowdok/binary-sphere-ollama.git
   ```
   
## Installation d'un environnement virtuel Python

   **√âtapes (Terminal/Command Prompt)**

### Cr√©er un environnement virtuel avec Windows

**Naviguez vers le dossier de votre projet**

   '''bash
   cd chemin/vers/votre/projet
   '''

**Cr√©er l'environnement virtuel**

   '''bash
   python -m venv venv
   '''
**Activer l'environnement virtuel**

   '''bash
   venv\Scripts\activate
   '''

Une fois activ√©, vous devriez voir (venv) au d√©but de votre ligne de commande.

**D√©sactiver l'environnement virtuel (quand vous avez termin√©)**
deactivate


### Cr√©er un environnement virtuel avec macOS/Linux

**Naviguez vers le dossier de votre projet**

   '''bash
   cd chemin/vers/votre/projet
   '''

**Cr√©er l'environnement virtuel**

   '''bash
   python3 -m venv venv
   '''
**Activer l'environnement virtuel**

   '''bash
   source venv/bin/activate
   '''

Une fois activ√©, vous devriez voir (venv) au d√©but de votre ligne de commande.

**D√©sactiver l'environnement virtuel (quand vous avez termin√©)**
deactivate


## Installer les d√©pendances Python

   ```bash
   pip install -r requirements.txt
   ```

**Assurez-vous qu'Ollama est install√©**
   
   Suivez les instructions sur [https://ollama.ai/]

**V√©rifiez que votre mod√®le Ollama est disponible**

   ```bash
   ollama list
   ```
   
   Si vous n'avez pas `llama3.2:1b-instruct-q8_0`, vous pouvez le t√©l√©charger ou utiliser un autre mod√®le:
   
   ```bash
   ollama pull llama3.2:1b-instruct-q8_0
   ```

## üîß Configuration

Avant de d√©marrer, vous pouvez ajuster les param√®tres (ou personnaliser) dans les fichiers:

### Serveur Python (quote-server.py)

- Modifiez le nom du mod√®le Ollama si n√©cessaire
- Ajustez les options de g√©n√©ration (temp√©rature, etc.)

### Interface HTML (earth-binary-sphere-with-proxy.html)

Vous pouvez modifier les param√®tres de configuration dans l'objet `CONFIG`:

```javascript
const CONFIG = {
    apiEndpoint: 'http://127.0.0.1:5000/quote', // API Python locale
    statusEndpoint: 'http://127.0.0.1:5000/status', // V√©rification du statut
    checkInterval: 5000,  // V√©rifier la connexion toutes les 5 secondes
    quoteInterval: 13000,  // Changer de citation toutes les 13 secondes
    maxStoredQuotes: 50,   // Nombre maximum de citations √† stocker
    minQuotesToDisplay: 1, // Minimum de citations avant d'afficher
    historySize: 12,       // Citations r√©centes √† ne pas r√©p√©ter
    maxTries: 15           // Essais max pour trouver une citation non-r√©p√©t√©e
};
```

## ‚ñ∂Ô∏è Utilisation

1. **D√©marrer le serveur Python en premier**

   ```bash
   python quote-server.py
   ```

   Un message confirmera que le serveur est en cours d'ex√©cution sur `http://127.0.0.1:5000/`

2. **Ouvrir le fichier HTML dans votre navigateur**

   Ouvrez `earth-binary-sphere-with-proxy.html` dans votre navigateur web pr√©f√©r√©.

3. **Profitez de l'exp√©rience**

   - Le point vert en bas √† droite indique que la connexion avec Ollama est √©tablie
   - Les citations alternent entre les deux c√¥t√©s de l'√©cran
   - La sph√®re binaire tourne lentement avec des chiffres qui clignotent
   - Personnaliser comme vous le voulez

## üìÅ Structure des fichiers

- **quote-server.py** : Serveur Python qui communique avec Ollama et expose une API REST
- **earth-binary-sphere-with-proxy.html** : Interface web avec la sph√®re 3D et l'affichage heure, date et des citations
- **requirements.txt** : D√©pendances Python n√©cessaires

## üîç Fonctionnement

1. Le serveur Python √©tablit une connexion avec Ollama
2. L'interface web se connecte au serveur Python
3. Lorsqu'une citation est demand√©e, le serveur interroge Ollama
4. Ollama g√©n√®re une citation inspirante
5. La citation est renvoy√©e √† l'interface et affich√©e

## üîÑ Syst√®me anti-r√©p√©tition

Le syst√®me garde en m√©moire les 12 derni√®res citations affich√©es et √©vite de les montrer √† nouveau tant que d'autres citations sont disponibles. Cela garantit une exp√©rience vari√©e, m√™me avec un nombre limit√© de citations g√©n√©r√©es.

## üì± Compatibilit√©

- ‚úÖ Desktop (Chrome, Firefox, Safari, Edge)
- ‚ùå Internet Explorer (non support√©)

## üìù Licence

Ce projet est distribu√© sous la licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus d'informations.

## üôè Cr√©dits

- Ollama pour la g√©n√©ration de texte by prompt Blowdok
- Flask et Flask-CORS pour l'API Python

---

Cr√©√© avec ‚ù§Ô∏è par Blowdok alias BlowCoder 
