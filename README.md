# Sph√®re Binaire avec Citations IA g√©n√©rer dynamiquement

Une visualisation 3D immersive d'une sph√®re binaire (0 et 1) avec des citations g√©n√©r√©es par un mod√®le de langage Ollama.

## üåü Fonctionnalit√©s

- Sph√®re 3D interactive avec chiffres binaires lumineux
- Affichage de l'heure et de la date en temps r√©el
- Citations g√©n√©r√©es par votre mod√®le Ollama local
- Syst√®me anti-r√©p√©tition pour les citations
- Interface visuelle √©l√©gante en noir et effets lumineux

## üìã Pr√©requis

- [Ollama](https://ollama.ai/) install√© et configur√©
- Un mod√®le Ollama (par d√©faut: `llama3.2:1b-instruct-q8_0`)
- Python 3.7+ et pip
- Un navigateur web moderne

## üöÄ Installation

1. **Cloner ou t√©l√©charger ce d√©p√¥t**

## Installation d'un environnement virtuel Python

√âtapes (Terminal/Command Prompt)
1. Cr√©er un environnement virtuel

Windows:
## Naviguez vers le dossier de votre projet
cd chemin/vers/votre/projet
## Cr√©er l'environnement virtuel
python -m venv venv
## Activer l'environnement virtuel
venv\Scripts\activate

Une fois activ√©, vous devriez voir (venv) au d√©but de votre ligne de commande.
## D√©sactiver l'environnement virtuel (quand vous avez termin√©)
deactivate

macOS/Linux:
## Naviguez vers le dossier de votre projet
cd chemin/vers/votre/projet
## Cr√©er l'environnement virtuel
python3 -m venv venv
## Activer l'environnement virtuel
source venv/bin/activate
Une fois activ√©, vous devriez voir (venv) au d√©but de votre ligne de commande.
## D√©sactiver l'environnement virtuel (quand vous avez termin√©)
deactivate

2. **Installer les d√©pendances Python**

   ```bash
   pip install -r requirements.txt
   ```

3. **Assurez-vous qu'Ollama est install√©**
   
   Suivez les instructions sur [https://ollama.ai/]

4. **V√©rifiez que votre mod√®le Ollama est disponible**

   ```bash
   ollama list
   ```
   
   Si vous n'avez pas `llama3.2:1b-instruct-q8_0`, vous pouvez le t√©l√©charger ou utiliser un autre mod√®le:
   
   ```bash
   ollama pull llama3.2:1b-instruct-q8_0
   ```

## üîß Configuration

Avant de d√©marrer, vous pouvez ajuster les param√®tres dans les fichiers:

### Serveur Python (quote-server.py)

- Modifiez le nom du mod√®le Ollama si n√©cessaire (ligne 15)
- Ajustez les options de g√©n√©ration (temp√©rature, etc.)

### Interface HTML (earth-binary-sphere-with-proxy.html)

Vous pouvez modifier les param√®tres de configuration dans l'objet `CONFIG` (vers la ligne 420):

```javascript
const CONFIG = {
    apiEndpoint: 'http://127.0.0.1:5000/quote', // API Python locale
    statusEndpoint: 'http://127.0.0.1:5000/status', // V√©rification du statut
    checkInterval: 5000,  // V√©rifier la connexion toutes les 5 secondes
    quoteInterval: 13000,  // Changer de citation toutes les 13 secondes
    maxStoredQuotes: 50,   // Nombre maximum de citations √† stocker
    minQuotesToDisplay: 1, // Minimum de citations avant d'afficher
    historySize: 12,       // Citations r√©centes √† ne pas r√©p√©ter
    maxTries: 15           // Essais max pour trouver une citation non-r√©p√©t√©e
};
```

## ‚ñ∂Ô∏è Utilisation

1. **D√©marrer le serveur Python en premier**

   ```bash
   python quote-server.py
   ```

   Un message confirmera que le serveur est en cours d'ex√©cution sur `http://127.0.0.1:5000/`

2. **Ouvrir le fichier HTML dans votre navigateur**

   Ouvrez `earth-binary-sphere-with-proxy.html` dans votre navigateur web pr√©f√©r√©.

3. **Profitez de l'exp√©rience**

   - Le point vert en bas √† droite indique que la connexion avec Ollama est √©tablie
   - Les citations alternent entre les deux c√¥t√©s de l'√©cran
   - La sph√®re binaire tourne lentement avec des chiffres qui clignotent

## üìÅ Structure des fichiers

- **quote-server.py** - Serveur Python qui communique avec Ollama et expose une API REST
- **earth-binary-sphere-with-proxy.html** - Interface web avec la sph√®re 3D et l'affichage des citations
- **requirements.txt** - D√©pendances Python n√©cessaires

## üîç Fonctionnement

1. Le serveur Python √©tablit une connexion avec Ollama
2. L'interface web se connecte au serveur Python
3. Lorsqu'une citation est demand√©e, le serveur interroge Ollama
4. Ollama g√©n√®re une citation inspirante
5. La citation est renvoy√©e √† l'interface et affich√©e

## üîÑ Syst√®me anti-r√©p√©tition

Le syst√®me garde en m√©moire les 12 derni√®res citations affich√©es et √©vite de les montrer √† nouveau tant que d'autres citations sont disponibles. Cela garantit une exp√©rience vari√©e, m√™me avec un nombre limit√© de citations g√©n√©r√©es.

## üì± Compatibilit√©

- ‚úÖ Desktop (Chrome, Firefox, Safari, Edge)
- ‚úÖ Mobile (versions r√©centes des navigateurs)
- ‚ùå Internet Explorer (non support√©)

## üìù Licence

Ce projet est distribu√© sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

## üôè Cr√©dits

- Three.js pour le rendu 3D
- Ollama pour la g√©n√©ration de texte
- Flask et Flask-CORS pour l'API Python

---

Cr√©√© avec ‚ù§Ô∏è par Blowdok alias BlowCoder
"# binary-sphere-ollama" 
